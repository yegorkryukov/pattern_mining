{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the Apriori algorithm and use it to mine category sets that are frequent in the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Breakfast & Brunch', 'American (Traditional)', 'Restaurants'],\n",
       " ['Sandwiches', 'Restaurants'],\n",
       " ['Local Services', 'IT Services & Computer Repair'],\n",
       " ['Restaurants', 'Italian'],\n",
       " ['Food', 'Coffee & Tea']]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('categories.txt', 'r') as f:\n",
    "    data = f.read().split('\\n')\n",
    "data = [l.split(';') for l in data]\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "\n",
    "Please output all the length-1 frequent categories with their absolute supports into a text file named \"patterns.txt\". Every line corresponds to exactly one frequent category and should be in the following format:\n",
    "\n",
    "`support:category`\n",
    "\n",
    "For example, suppose a category (Fast Food) has an absolute support 3000, then the line corresponding to this frequent category set in \"patterns.txt\" should be:\n",
    "\n",
    "`3000:Fast Food`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_C1(D, min_sup:int=None):\n",
    "    C1 = defaultdict(int)\n",
    "    for transaction in D:\n",
    "        for item in transaction:\n",
    "            C1[frozenset([item])] += 1\n",
    "    return C1\n",
    "\n",
    "def get_above_min_sup(C:dict, min_sup:int):\n",
    "    L_sup = C.copy()\n",
    "    for key in C:\n",
    "        if C[key] < min_sup: L_sup.pop(key)\n",
    "    return L_sup\n",
    "\n",
    "min_sup = 771\n",
    "C1 = get_C1(data, min_sup=min_sup)\n",
    "L1 = get_above_min_sup(C1, min_sup=min_sup)\n",
    "\n",
    "with open('1/patterns.txt', 'w') as f:\n",
    "    f.write(\n",
    "        '\\n'.join([f'{v}:{list(k)[0]}' for (k, v) in\n",
    "                   sorted(L1.items(), key=lambda item: item[1], reverse=True)])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "Please write all the frequent category sets along with their absolute supports into a text file named \"patterns.txt\". Every line corresponds to exactly one frequent category set and should be in the following format:\n",
    "\n",
    "`support:category_1;category_2;category_3;...`\n",
    "\n",
    "For example, suppose a category set (Fast Food; Restaurants) has an absolute support 2851, then the line corresponding to this frequent category set in \"patterns.txt\" should be:\n",
    "\n",
    "`2851:Fast Food;Restaurants`\n",
    "\n",
    "**Important Tips**\n",
    "\n",
    "Make sure that you format each line correctly in the output file. For instance, use a semicolon instead of another character to separate the categories for each frequent category set. \n",
    "\n",
    "In the result pattern file, the order of the categories does not matter. For example, the following two cases will be considered equivalent by the grader:\n",
    "\n",
    "Case 1:\n",
    "\n",
    "`2851:Fast Food;Restaurants`\n",
    "\n",
    "Case 2:\n",
    "\n",
    "`2851:Restaurants;Fast Food `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-22 09:31:50.126965: k=2\n",
      "Got len(Ck):1225, len(Ct):598\n",
      "2021-03-22 09:32:05.164178: k=3\n",
      "Got len(Ck):8, len(Ct):8\n",
      "2021-03-22 09:32:05.268834: k=4\n",
      "Got len(Ck):0, len(Ct):0\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from datetime import datetime\n",
    "\n",
    "def get_union(itemSet, length):\n",
    "    return set([i.union(j) for i in itemSet for j in itemSet if len(i.union(j)) == length])\n",
    "\n",
    "def pruning(Ck, Lkprev, length):\n",
    "    temp = Ck.copy()\n",
    "    for item in Ck:\n",
    "        subsets = combinations(item, length)\n",
    "        for subset in subsets:\n",
    "            # if the subset is not in previous K-frequent get, then remove the set\n",
    "            if(frozenset(subset) not in Lkprev):\n",
    "                temp.remove(item)\n",
    "                break\n",
    "    return temp\n",
    "  \n",
    "def apriori_gen(Lk, k):\n",
    "    \"\"\"Generates candidates and eliminates itemsets that are not frequent\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    Lk : dict\n",
    "        {<itemset>:<support count>}\n",
    "    k : int\n",
    "        itemset 'order'\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    Ck : dict\n",
    "        candidate itemset\n",
    "    \"\"\"\n",
    "    \n",
    "    Ck = get_union(Lk, k)\n",
    "    Ck = pruning(Ck, Lk, k-1)\n",
    "    \n",
    "    return Ck\n",
    "\n",
    "D = list(map(frozenset, data))\n",
    "L = [None]\n",
    "L.append(L1)\n",
    "L_final = L1.copy()\n",
    "k = 2\n",
    "while (len(L[k-1]) > 0):\n",
    "    print(f'{datetime.now()}: k={k}')\n",
    "    Ck = apriori_gen(list(L[k-1].keys()), k)\n",
    "    Ct = defaultdict(int)\n",
    "    for transaction in D:\n",
    "        for can in Ck:\n",
    "            if can.issubset(transaction):\n",
    "                Ct[can] += 1\n",
    "    print(f'Got len(Ck):{len(Ck)}, len(Ct):{len(Ct)}')\n",
    "    Lk = get_above_min_sup(Ct, min_sup=min_sup)\n",
    "    L.append(Lk)\n",
    "    L_final.update(Lk)\n",
    "    k += 1\n",
    "\n",
    "with open('2/patterns.txt', 'w') as f:\n",
    "    f.write(\n",
    "        '\\n'.join([f'{v}:{\";\".join(list(k))}' for (k, v) in\n",
    "                   sorted(L_final.items(), key=lambda item: item[1], reverse=True)])\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
